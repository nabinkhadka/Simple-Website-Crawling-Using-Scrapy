# Simple-Website-Crawling-Using-Scrapy
A simple use case for Scrapy

Use:
1. Create a virtual environment `virtualenv projectenv`
2. Activate it `source projectenv/bin/activate`
3. Move into the cloned project `cd Simple-Website-Crawling-Using-Scrapy`
4. Install dependencies `pip install -r requirements.txt`
5. Move into the feedreader directory `cd feedreader`
6. Run the spider using `scrapy crawl feedreaderspider`
